\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsthm}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{float}
% graphics
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

 \hypersetup{
     colorlinks=true,
     linkcolor=blue,
     filecolor=blue,
     citecolor = black,
     urlcolor=cyan,
     }


\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}[section]

\setlength{\parindent}{2em}

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }}

% Update your Headers here
\fancyhead[LO]{UGP, 21-22 Even Semester}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}




%% Title
\title{Updates - MITACS project
%%%% Cite as
%%%% Update your official citation here when published
%\thanks{\textit{\underline{Citation}}:
%\textbf{Authors. Title. Pages.... DOI:000000/11111.}}
}

% \author{
%   Vivek Kumar Singh \\
%   Bachelor of Science \\
%   Department of Mathematics and Statistics \\
%   Indian Institute of Technology Kanpur \\
%   % City\\
%   \texttt{\{vksingh\}@iitk.ac.in} \\
%   %% examples of more authors
%    \And
%   Dootika Vats \\
%   Associate Professor \\
%   Department of Mathematics and Statistics \\
%   Indian Institute of Technology Kanpur \\
%  % City\\
%  \texttt{\{dootika\}@iitk.ac.in}
%   %% \AND
%   %% Coauthor \\
%   %% Affiliation \\
%   %% Address \\
%   %% \texttt{email} \\
%   %% \And
%   %% Coauthor \\
%   %% Affiliation \\
%   %% Address \\
%   %% \texttt{email} \\
%   %% \And
%   %% Coauthor \\
%   %% Affiliation \\
%   %% Address \\
%   %% \texttt{email} \\
% }


\begin{document}
\maketitle
	\section{Week 1}
		\subsection{Deciding on the project}
			We talked about three project ideas
			\begin{enumerate}
				\item Explicit block couplings on "symmetric", "big" $\Omega$'s.\\
					Eg. The Ising model on $\mathbb{Z}^2_n$
				\item Existence of MMC's
					Look at prof Aaron's notes on MMC.
				\item Computing couplings for stats. (Eg. work done by Jacob Pierre)\\
					Read: Pierre's notes on Couplings
			\end{enumerate}
			I decided to try the third one first.

		\subsection{To proceed on the third project}
			There were three tasks to be done.
			\begin{enumerate}
				\item Set up dropbox to write notes\\
					\Update: Done.
				\item Find Pierre's notes on Couplings and read a bit.\\
					\Update: I found the notes. I'm reading them up, and will be done with 3 chapters of it by our next meeting (I guess on Tuesday)
				\item Try a simple example (Suggestion : MH algoritm on $N(0, 1)$ with mirror and maximal)\\

			\end{enumerate}

	\section{Week 2}
		\begin{itemize}
			\item Created a github repo for the whole project.
			\item Coded up MH on N(0, 1) using the maximal couplings. \\
			The algorithm is as follows: \\
			Let $K$ be the kernel for the MH algo. At any point $X_0, Y_0$ of the chain, define the point-wise maxima as $\Pi_{X_0, Y_0}(\cdot) = \min(K(X_0, \cdot), K(Y_0, \cdot))$.\\
			Define the residuals as $r_{X_0}(\cdot) = K(X_0, \cdot) - \Pi_{X_0, Y_0}(\cdot)$ and $r_{Y_0}(\cdot) = K(Y_0, \cdot) - \Pi_{X_0, Y_0}(\cdot)$.\\
			Algorithm: \\
			w.p. $\Pi_{X_0, Y_0}(\mathbb{1})$, choose
				$$X_1 = Y_1 \sim \Pi_{X_0, Y_0}(\cdot)/\Pi_{X_0, Y_0}(\mathbb{1})$$
			Otherwise
				$$X_1 \sim r_{X_0}(\cdot)/r_{X_0}(\mathbb{1})$$
				$$Y_1 \sim r_{Y_0}(\cdot)/r_{Y_0}(\mathbb{1})$$
			Repeat the above steps to get the chain $(X_n)$ and $(Y_n)$

			\item Studied maximal coupling, optimal transport coupling, total variation norm, weisserstein distances.
			\item Meeting \#2 with Aaron:
				\begin{itemize}
					\item Discussed about when a coupling is faithful, coupling inequality and mixing time in our context.\\
					A coupling is said to be "good/faithful/stichy" if :
					$$\forall s>\Gamma_{\text{hit}}, X_s = Y_s,$$
					$$\text{where, } \Gamma_{\text{hit}}(x, y) = \min\{s: X_s = Y_s, X_0 = x, Y_0 = y\}$$
					\begin{theorem}
						$$||K^s(x, \cdot) - K^s(y, \cdot)||_{\text{TV}} \leq \Pr(\Gamma_{\text{hit}}(x, y) > s)$$
					\end{theorem}
					\begin{corollary}
						$$\Gamma_{\text{mix}}(\epsilon) \leq \min\{s : \max_{x, y} \Pr(\Gamma_{\text{hit}}(x, y) > s) \leq \epsilon\}$$
					\end{corollary}
					\item Discussed the main idea of Broderick et al's paper. The setting of the problem is basically we have a lot of vertices with +1 and -1 labellings.
					We want to connect them using edges to make a graph such that the energy of the graph is as minimum as possible (energy is lower if we minimize the number of edges between opposite signed vertices)
					This is kind of like a clustering problem. The problem is to draw from configurations like these.\\
					Energy of a particular configuration is of the form $H(\sigma) = -\sum_{(i, j) \in E} \sigma(i)\sigma(j)$, where $\sigma(i)$ denotes the label of the vertex of a particular configuration.\\
					The probability density is then of the form $p(\sigma) \propto \exp(-\beta H(\sigma))$ (doubt: what exactly are we drawing from this distribution, how to do it?)\\
					As there is no difference if we switch the labels in our case, we take the space to be $\overline{\Sigma} = \Sigma/(\text{flip})$
					\item The paper doesn't contribute much theoretically but is very well written. The work done is on a computer and some new things and ideas are presented. The aim of our project is to take one of the below presented problems, try to make some progress in them and write a Broderick style paper on it.
					\item We then discussed the following three problems:
						\begin{enumerate}
							\item NNMF : The problem is that we have a very large matrix and we need to decompose it into product of smaller dimension matrices such that the energy is minimized. \\
							$A \approx C^tR$, $H(C, R) \approx ||C|| + ||R|| + ||A-C^tR||$ (\todo: different norms are used, fill it up after reading the paper)\\
							Then draw from the defined distribution. $p(C, R) \propto \exp(-\beta H(C, R))$\\
							This is also similar to the classification problem, just not very obvious. (\todo: read the paper to understand why this problem is also similar to a classification problem)
							\item Ranking : Observe games $g_1(h_1, a_1) \dots g_N(h_N, a_N) \in \{-1, 1\}$, $h_i, a_i \in \{1, \dots, n\}/\Delta$, n: \#teams, N: \#games\\
							Based on the win/lose data, we try to rank them so that the energy is minimized. Energy is as follows: $H(\sigma) = \sum_{i = 1}^N \mathbb{1}_{\sigma(h_i)>\sigma{a_i}}\cdot\mathbb{1}_{g_i(h_i, a_i) = 1}$ (\todo: get a symmetric formula for energy (HINT: use the bradley-terry model)).\\
							Then draw from the probability distribution defined as $p(\sigma) \propto \exp(-\beta H(\sigma))$.\\
							This problem for $\beta = 0$ is called the random transposition walk (like glauber dynamics)
							\item Q: What happens when $\beta$ is small. Problem is a similar phenomenon to Gibbs algo on simplexes.
						\end{enumerate}
				\end{itemize}
			\item Studied convergence of Markov chains and application of coupling techniques to prove convergence.
		\end{itemize}

	\section{Week 3}
		Tasks for the week
		\begin{itemize}
			\item Complete Jacob's notes and lecture videos
			\item Broderick's paper
   			\item Study more about these problems, try to work out some details
      		\item Try to read Lindvall :)
		\end{itemize}




\end{document}